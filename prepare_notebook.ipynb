{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b47aee71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "import re\n",
    "import json\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import acquire as aq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41eb25f6",
   "metadata": {},
   "source": [
    "#### 1. Define a function named basic_clean. It should take in a string and apply some basic text cleaning to it:\n",
    "\n",
    "- Lowercase everything\n",
    "- Normalize unicode characters\n",
    "- Replace anything that is not a letter, number, whitespace or a single quote."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fe3f3a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mess = \"A lazy 7 DoG's that HOppEd 15 tImes! @ 10 O'Clock the cat t[ook a ;shot. but WHY???\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8dcaf246",
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_clean(text):\n",
    "    text = text.lower()\n",
    "    text = unicodedata.normalize('NFKD', text)\\\n",
    "        .encode('ascii', 'ignore')\\\n",
    "        .decode('utf-8', 'ignore')\n",
    "    text = re.sub(r\"[^a-z0-9\\s]\", '', text)\n",
    "    return text\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1b66e450",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a lazy 7 dogs that hopped 15 times  10 oclock the cat took a shot but why'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean = basic_clean(mess)\n",
    "clean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9217395",
   "metadata": {},
   "source": [
    "### 2. Define a function named tokenize. It should take in a string and tokenize all the words in the string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28f9bf82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    tokenizer = nltk.tokenize.ToktokTokenizer()\n",
    "    return tokenizer.tokenize(text, return_str=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "26802c42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a lazy 7 dogs that hopped 15 times 10 oclock the cat took a shot but why'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokened = tokenize(clean)\n",
    "tokened"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de94928d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "44d65586",
   "metadata": {},
   "source": [
    "### 3. Define a function named stem. It should accept some text and return the text after applying stemming to all the words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "89f8deef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem(text):\n",
    "    ps = nltk.porter.PorterStemmer()\n",
    "    words = text.split()\n",
    "    stems = [ps.stem(word) for word in words]\n",
    "    return ' '.join(stems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b1539594",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a lazi 7 dog that hop 15 time 10 oclock the cat took a shot but whi'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmed = stem(tokened)\n",
    "stemmed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "721fd380",
   "metadata": {},
   "source": [
    "### 4. Define a function named lemmatize. It should accept some text and return the text after applying lemmatization to each word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30bd5854",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize(text):\n",
    "    wnl = nltk.stem.WordNetLemmatizer()\n",
    "    lemmas = [wnl.lemmatize(word) for word in text.split()]\n",
    "    return ' '.join(lemmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c2d2cd0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a lazy 7 dog that hopped 15 time 10 oclock the cat took a shot but why'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmed = lemmatize(tokened)\n",
    "lemmed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f09ca3",
   "metadata": {},
   "source": [
    "### 5. Define a function named remove_stopwords. It should accept some text and return the text after removing all the stopwords.\n",
    "\n",
    "This function should define two optional parameters, extra_words and exclude_words. These parameters should define any additional stop words to include, and any words that we don't want to remove."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42f9ec14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(text, stopword_list=stopwords.words('english')):\n",
    "    words = text.split()\n",
    "    filtered_words = [word for word in words if word not in stopword_list]\n",
    "    return ' '.join(filtered_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5fd7a535",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'lazi 7 dog hop 15 time 10 oclock cat took shot whi'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stm = remove_stopwords(stemmed)\n",
    "stm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "48a3226e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'lazy 7 dog hopped 15 time 10 oclock cat took shot'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm = remove_stopwords(lemmed)\n",
    "lm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f31cefa9",
   "metadata": {},
   "source": [
    "### 6. Use your data from the acquire to produce a dataframe of the news articles. Name the dataframe news_df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "504d0904",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading from local CSV...\n"
     ]
    }
   ],
   "source": [
    "news_df = aq.get_news_articles()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00df7900",
   "metadata": {},
   "source": [
    "### 7. Make another dataframe for the Codeup blog posts. Name the dataframe codeup_df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "61a5b6fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading from local CSV...\n"
     ]
    }
   ],
   "source": [
    "codeup_df = aq.get_blog_articles()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ebc94e",
   "metadata": {},
   "source": [
    "### 8. For each dataframe, produce the following columns:\n",
    "\n",
    "- title to hold the title\n",
    "- original to hold the original article/post content\n",
    "- clean to hold the normalized and tokenized original with the stopwords removed.\n",
    "- stemmed to hold the stemmed version of the cleaned data.\n",
    "- lemmatized to hold the lemmatized version of the cleaned data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e12b7010",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nlp_prep(df):\n",
    "    df = df.rename(columns={'content':'original'})\n",
    "    df['clean'] = (df.original.apply(basic_clean)\n",
    "                     .apply(tokenize)\n",
    "                     .apply(remove_stopwords)\n",
    "                  )\n",
    "    df['stemmed'] = df.clean.apply(stem)\n",
    "    df['lemmatized'] = df.clean.apply(lemmatize)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "af547e91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>content</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>India's GDP grows at 13.5% in first quarter of...</td>\n",
       "      <td>Anmol Sharma</td>\n",
       "      <td>India's GDP grew at 13.5% in the first quarter...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title        author  \\\n",
       "0  India's GDP grows at 13.5% in first quarter of...  Anmol Sharma   \n",
       "\n",
       "                                             content  category  \n",
       "0  India's GDP grew at 13.5% in the first quarter...  business  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d8b83f94",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>original</th>\n",
       "      <th>category</th>\n",
       "      <th>clean</th>\n",
       "      <th>stemmed</th>\n",
       "      <th>lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>India's GDP grows at 13.5% in first quarter of...</td>\n",
       "      <td>Anmol Sharma</td>\n",
       "      <td>India's GDP grew at 13.5% in the first quarter...</td>\n",
       "      <td>business</td>\n",
       "      <td>indias gdp grew 135 first quarter fy23 achievi...</td>\n",
       "      <td>india gdp grew 135 first quarter fy23 achiev f...</td>\n",
       "      <td>india gdp grew 135 first quarter fy23 achievin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Snap to lay off 20% of staff, cancel several p...</td>\n",
       "      <td>Ananya Goyal</td>\n",
       "      <td>Snap said on Wednesday it will lay off 20% of ...</td>\n",
       "      <td>business</td>\n",
       "      <td>snap said wednesday lay 20 staff shut original...</td>\n",
       "      <td>snap said wednesday lay 20 staff shut origin s...</td>\n",
       "      <td>snap said wednesday lay 20 staff shut original...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2 top executives at Snap quit hours after repo...</td>\n",
       "      <td>Ridham Gambhir</td>\n",
       "      <td>Two senior advertising executives at Snap quit...</td>\n",
       "      <td>business</td>\n",
       "      <td>two senior advertising executives snap quit ho...</td>\n",
       "      <td>two senior advertis execut snap quit hour repo...</td>\n",
       "      <td>two senior advertising executive snap quit hou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Musk seeks to delay Twitter trial to Nov amid ...</td>\n",
       "      <td>Ridham Gambhir</td>\n",
       "      <td>Tesla CEO Elon Musk is seeking to delay the tr...</td>\n",
       "      <td>business</td>\n",
       "      <td>tesla ceo elon musk seeking delay trial twitte...</td>\n",
       "      <td>tesla ceo elon musk seek delay trial twitter n...</td>\n",
       "      <td>tesla ceo elon musk seeking delay trial twitte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Viral video shows Amazon parcels thrown out of...</td>\n",
       "      <td>Apaar Sharma</td>\n",
       "      <td>A video from Guwahati railway station has gone...</td>\n",
       "      <td>business</td>\n",
       "      <td>video guwahati railway station gone viral show...</td>\n",
       "      <td>video guwahati railway station gone viral show...</td>\n",
       "      <td>video guwahati railway station gone viral show...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title          author  \\\n",
       "0  India's GDP grows at 13.5% in first quarter of...    Anmol Sharma   \n",
       "1  Snap to lay off 20% of staff, cancel several p...    Ananya Goyal   \n",
       "2  2 top executives at Snap quit hours after repo...  Ridham Gambhir   \n",
       "3  Musk seeks to delay Twitter trial to Nov amid ...  Ridham Gambhir   \n",
       "4  Viral video shows Amazon parcels thrown out of...    Apaar Sharma   \n",
       "\n",
       "                                            original  category  \\\n",
       "0  India's GDP grew at 13.5% in the first quarter...  business   \n",
       "1  Snap said on Wednesday it will lay off 20% of ...  business   \n",
       "2  Two senior advertising executives at Snap quit...  business   \n",
       "3  Tesla CEO Elon Musk is seeking to delay the tr...  business   \n",
       "4  A video from Guwahati railway station has gone...  business   \n",
       "\n",
       "                                               clean  \\\n",
       "0  indias gdp grew 135 first quarter fy23 achievi...   \n",
       "1  snap said wednesday lay 20 staff shut original...   \n",
       "2  two senior advertising executives snap quit ho...   \n",
       "3  tesla ceo elon musk seeking delay trial twitte...   \n",
       "4  video guwahati railway station gone viral show...   \n",
       "\n",
       "                                             stemmed  \\\n",
       "0  india gdp grew 135 first quarter fy23 achiev f...   \n",
       "1  snap said wednesday lay 20 staff shut origin s...   \n",
       "2  two senior advertis execut snap quit hour repo...   \n",
       "3  tesla ceo elon musk seek delay trial twitter n...   \n",
       "4  video guwahati railway station gone viral show...   \n",
       "\n",
       "                                          lemmatized  \n",
       "0  india gdp grew 135 first quarter fy23 achievin...  \n",
       "1  snap said wednesday lay 20 staff shut original...  \n",
       "2  two senior advertising executive snap quit hou...  \n",
       "3  tesla ceo elon musk seeking delay trial twitte...  \n",
       "4  video guwahati railway station gone viral show...  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_df = nlp_prep(news_df)\n",
    "news_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "06945337",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>original</th>\n",
       "      <th>clean</th>\n",
       "      <th>stemmed</th>\n",
       "      <th>lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Is a Career in Tech Recession-Proof?</td>\n",
       "      <td>Given the current economic climate, many econo...</td>\n",
       "      <td>given current economic climate many economists...</td>\n",
       "      <td>given current econom climat mani economist con...</td>\n",
       "      <td>given current economic climate many economist ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Codeup X Superhero Car Show &amp; Comic Con</td>\n",
       "      <td>Codeup had a blast at the San Antonio Superher...</td>\n",
       "      <td>codeup blast san antonio superhero car show co...</td>\n",
       "      <td>codeup blast san antonio superhero car show co...</td>\n",
       "      <td>codeup blast san antonio superhero car show co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What Jobs Can You Get After a Coding Bootcamp?...</td>\n",
       "      <td>If you’re considering a career in web developm...</td>\n",
       "      <td>youre considering career web development dont ...</td>\n",
       "      <td>your consid career web develop dont know expec...</td>\n",
       "      <td>youre considering career web development dont ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Codeup’s New Dallas Campus</td>\n",
       "      <td>Codeup’s Dallas campus has a new location! For...</td>\n",
       "      <td>codeups dallas campus new location two years c...</td>\n",
       "      <td>codeup dalla campu new locat two year codeup o...</td>\n",
       "      <td>codeups dallas campus new location two year co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Codeup TV Commercial</td>\n",
       "      <td>Codeup has officially made its TV debut! Our c...</td>\n",
       "      <td>codeup officially made tv debut community stud...</td>\n",
       "      <td>codeup offici made tv debut commun student sta...</td>\n",
       "      <td>codeup officially made tv debut community stud...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0               Is a Career in Tech Recession-Proof?   \n",
       "1            Codeup X Superhero Car Show & Comic Con   \n",
       "2  What Jobs Can You Get After a Coding Bootcamp?...   \n",
       "3                         Codeup’s New Dallas Campus   \n",
       "4                               Codeup TV Commercial   \n",
       "\n",
       "                                            original  \\\n",
       "0  Given the current economic climate, many econo...   \n",
       "1  Codeup had a blast at the San Antonio Superher...   \n",
       "2  If you’re considering a career in web developm...   \n",
       "3  Codeup’s Dallas campus has a new location! For...   \n",
       "4  Codeup has officially made its TV debut! Our c...   \n",
       "\n",
       "                                               clean  \\\n",
       "0  given current economic climate many economists...   \n",
       "1  codeup blast san antonio superhero car show co...   \n",
       "2  youre considering career web development dont ...   \n",
       "3  codeups dallas campus new location two years c...   \n",
       "4  codeup officially made tv debut community stud...   \n",
       "\n",
       "                                             stemmed  \\\n",
       "0  given current econom climat mani economist con...   \n",
       "1  codeup blast san antonio superhero car show co...   \n",
       "2  your consid career web develop dont know expec...   \n",
       "3  codeup dalla campu new locat two year codeup o...   \n",
       "4  codeup offici made tv debut commun student sta...   \n",
       "\n",
       "                                          lemmatized  \n",
       "0  given current economic climate many economist ...  \n",
       "1  codeup blast san antonio superhero car show co...  \n",
       "2  youre considering career web development dont ...  \n",
       "3  codeups dallas campus new location two year co...  \n",
       "4  codeup officially made tv debut community stud...  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "codeup_df = nlp_prep(codeup_df)\n",
    "codeup_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
