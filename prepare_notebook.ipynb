{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ecbb2317",
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "import re\n",
    "import json\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import acquire as aq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f9e0245",
   "metadata": {},
   "source": [
    "#### 1. Define a function named basic_clean. It should take in a string and apply some basic text cleaning to it:\n",
    "\n",
    "- Lowercase everything\n",
    "- Normalize unicode characters\n",
    "- Replace anything that is not a letter, number, whitespace or a single quote."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1cc6d026",
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_clean(text):\n",
    "    text = text.lower()\n",
    "    text = unicodedata.normalize('NFKD', text)\\\n",
    "        .encode('ascii', 'ignore')\\\n",
    "        .decode('utf-8', 'ignore')\n",
    "    text = re.sub(r\"[^a-z0-9'\\s]\", '', text)\n",
    "    return text\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "943b0063",
   "metadata": {},
   "source": [
    "### 2. Define a function named tokenize. It should take in a string and tokenize all the words in the string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "942aed2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    tokenizer = nltk.tokenize.ToktokTokenizer()\n",
    "    return tokenizer.tokenize(text, return_str=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb3a6254",
   "metadata": {},
   "source": [
    "### 3. Define a function named stem. It should accept some text and return the text after applying stemming to all the words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "833a73f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem(text):\n",
    "    ps = nltk.porter.PorterStemmer()\n",
    "    words = text.split()\n",
    "    stems = [ps.stem(word) for word in words]\n",
    "    return ' '.join(stems)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d49d78",
   "metadata": {},
   "source": [
    "### 4. Define a function named lemmatize. It should accept some text and return the text after applying lemmatization to each word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d2e1b554",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize(text):\n",
    "    wnl = nltk.stem.WordNetLemmatizer()\n",
    "    lemmas = [wnl.lemmatize(word) for word in text.split()]\n",
    "    return ' '.join(lemmas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e36e7633",
   "metadata": {},
   "source": [
    "### 5. Define a function named remove_stopwords. It should accept some text and return the text after removing all the stopwords.\n",
    "\n",
    "This function should define two optional parameters, extra_words and exclude_words. These parameters should define any additional stop words to include, and any words that we don't want to remove."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa5ed946",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(text, stopword_list=stopwords.words('english')):\n",
    "    words = text.split()\n",
    "    filtered_words = [word for word in words if word not in stopword_list]\n",
    "    return ' '.join(filtered_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c736202",
   "metadata": {},
   "source": [
    "### 6. Use your data from the acquire to produce a dataframe of the news articles. Name the dataframe news_df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "55315141",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading from local CSV...\n"
     ]
    }
   ],
   "source": [
    "news_df = aq.get_news_articles()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efeb4b1c",
   "metadata": {},
   "source": [
    "### 7. Make another dataframe for the Codeup blog posts. Name the dataframe codeup_df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3ee04b00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading from local CSV...\n"
     ]
    }
   ],
   "source": [
    "codeup_df = aq.get_blog_articles()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb7ae3ac",
   "metadata": {},
   "source": [
    "### 8. For each dataframe, produce the following columns:\n",
    "\n",
    "- title to hold the title\n",
    "- original to hold the original article/post content\n",
    "- clean to hold the normalized and tokenized original with the stopwords removed.\n",
    "- stemmed to hold the stemmed version of the cleaned data.\n",
    "- lemmatized to hold the lemmatized version of the cleaned data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aba20052",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nlp_prep(df):\n",
    "    df = df.rename(columns={'content':'original'})\n",
    "    df['clean'] = (df.original.apply(basic_clean)\n",
    "                     .apply(tokenize)\n",
    "                     .apply(remove_stopwords)\n",
    "                  )\n",
    "    df['stemmed'] = df.clean.apply(stem)\n",
    "    df['lemmatized'] = df.clean.apply(lemmatize)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ea3a0ccf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>content</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>India's GDP grows at 13.5% in first quarter of...</td>\n",
       "      <td>Anmol Sharma</td>\n",
       "      <td>India's GDP grew at 13.5% in the first quarter...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title        author  \\\n",
       "0  India's GDP grows at 13.5% in first quarter of...  Anmol Sharma   \n",
       "\n",
       "                                             content  category  \n",
       "0  India's GDP grew at 13.5% in the first quarter...  business  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "04d1fd8d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>original</th>\n",
       "      <th>category</th>\n",
       "      <th>clean</th>\n",
       "      <th>stemmed</th>\n",
       "      <th>lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>India's GDP grows at 13.5% in first quarter of...</td>\n",
       "      <td>Anmol Sharma</td>\n",
       "      <td>India's GDP grew at 13.5% in the first quarter...</td>\n",
       "      <td>business</td>\n",
       "      <td>india ' gdp grew 135 first quarter fy23 achiev...</td>\n",
       "      <td>india ' gdp grew 135 first quarter fy23 achiev...</td>\n",
       "      <td>india ' gdp grew 135 first quarter fy23 achiev...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Snap to lay off 20% of staff, cancel several p...</td>\n",
       "      <td>Ananya Goyal</td>\n",
       "      <td>Snap said on Wednesday it will lay off 20% of ...</td>\n",
       "      <td>business</td>\n",
       "      <td>snap said wednesday lay 20 staff shut original...</td>\n",
       "      <td>snap said wednesday lay 20 staff shut origin s...</td>\n",
       "      <td>snap said wednesday lay 20 staff shut original...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2 top executives at Snap quit hours after repo...</td>\n",
       "      <td>Ridham Gambhir</td>\n",
       "      <td>Two senior advertising executives at Snap quit...</td>\n",
       "      <td>business</td>\n",
       "      <td>two senior advertising executives snap quit ho...</td>\n",
       "      <td>two senior advertis execut snap quit hour repo...</td>\n",
       "      <td>two senior advertising executive snap quit hou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Musk seeks to delay Twitter trial to Nov amid ...</td>\n",
       "      <td>Ridham Gambhir</td>\n",
       "      <td>Tesla CEO Elon Musk is seeking to delay the tr...</td>\n",
       "      <td>business</td>\n",
       "      <td>tesla ceo elon musk seeking delay trial twitte...</td>\n",
       "      <td>tesla ceo elon musk seek delay trial twitter n...</td>\n",
       "      <td>tesla ceo elon musk seeking delay trial twitte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Viral video shows Amazon parcels thrown out of...</td>\n",
       "      <td>Apaar Sharma</td>\n",
       "      <td>A video from Guwahati railway station has gone...</td>\n",
       "      <td>business</td>\n",
       "      <td>video guwahati railway station gone viral show...</td>\n",
       "      <td>video guwahati railway station gone viral show...</td>\n",
       "      <td>video guwahati railway station gone viral show...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title          author  \\\n",
       "0  India's GDP grows at 13.5% in first quarter of...    Anmol Sharma   \n",
       "1  Snap to lay off 20% of staff, cancel several p...    Ananya Goyal   \n",
       "2  2 top executives at Snap quit hours after repo...  Ridham Gambhir   \n",
       "3  Musk seeks to delay Twitter trial to Nov amid ...  Ridham Gambhir   \n",
       "4  Viral video shows Amazon parcels thrown out of...    Apaar Sharma   \n",
       "\n",
       "                                            original  category  \\\n",
       "0  India's GDP grew at 13.5% in the first quarter...  business   \n",
       "1  Snap said on Wednesday it will lay off 20% of ...  business   \n",
       "2  Two senior advertising executives at Snap quit...  business   \n",
       "3  Tesla CEO Elon Musk is seeking to delay the tr...  business   \n",
       "4  A video from Guwahati railway station has gone...  business   \n",
       "\n",
       "                                               clean  \\\n",
       "0  india ' gdp grew 135 first quarter fy23 achiev...   \n",
       "1  snap said wednesday lay 20 staff shut original...   \n",
       "2  two senior advertising executives snap quit ho...   \n",
       "3  tesla ceo elon musk seeking delay trial twitte...   \n",
       "4  video guwahati railway station gone viral show...   \n",
       "\n",
       "                                             stemmed  \\\n",
       "0  india ' gdp grew 135 first quarter fy23 achiev...   \n",
       "1  snap said wednesday lay 20 staff shut origin s...   \n",
       "2  two senior advertis execut snap quit hour repo...   \n",
       "3  tesla ceo elon musk seek delay trial twitter n...   \n",
       "4  video guwahati railway station gone viral show...   \n",
       "\n",
       "                                          lemmatized  \n",
       "0  india ' gdp grew 135 first quarter fy23 achiev...  \n",
       "1  snap said wednesday lay 20 staff shut original...  \n",
       "2  two senior advertising executive snap quit hou...  \n",
       "3  tesla ceo elon musk seeking delay trial twitte...  \n",
       "4  video guwahati railway station gone viral show...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_df = nlp_prep(news_df)\n",
    "news_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69a92f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "code"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
